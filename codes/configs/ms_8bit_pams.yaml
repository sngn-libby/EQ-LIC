#============================ Quantization =====================================

quan:
  act: # (default for all layers)
    # Quantizer type (choices: lsq)
    mode: pams_act
    # Bit width of quantized activation
    bit: 8
  weight: # (default for all layers)
    # Quantizer type (choices: lsq)
    mode: pams_weight
    # Bit width of quantized weight
    bit: 8
  excepts:
    # Specify quantized bit width for some layers, like this:
    g_a.0:
      act:
        bit: 0
      weight:
        bit: 8
    g_s.6:
      act:
        bit: 8
      weight:
        bit: 8
